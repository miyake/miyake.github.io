<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/base.css">
  <title>miyake.github.io | 本の紹介 | 機械学習</title>
</head>

<body>

  <h1>本の紹介 : 機械学習</h1>

  <hr />
  <p>
  <a href="https://amzn.to/2RBpO50">Bishop 「パターン認識と機械学習 上」 (2012)</a>
  <a href="https://amzn.to/2rhY61U">「パターン認識と機械学習 下」 (2012)</a>
  </p>

  <p>
  1. 序論 <br />
  2. 確率分布 <br />
  3. 線形回帰モデル <br />
  4. 線形識別モデル <br />
  5. ニューラルネットワーク <br />
  6. カーネル法 <br />
  7. 疎な解を持つカーネルマシン <br />
  8. グラフィカルモデル <br />
  9. 混合モデルとEM <br />
  10. 近似推論法 <br />
  11. サンプリング法 <br />
  12. 連続潜在変数 <br />
  13. 系列データ <br />
  14. モデルの結合
  </p>

  <p>
  原書：
  <a href="https://amzn.to/2rldoTq">
    Bishop, Pattern Recognition and Machine Learning (2006)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Probability Distributions <br />
  3. Linear Models for Regression <br />
  4. Linear Models for Classification <br />
  5. Neural Networks <br />
  6. Kernel Methods <br />
  7. Sparse Kernel Machines <br />
  8. Graphical Models <br />
  9. Mixture Models and EM <br />
  10. Approximate Inference <br />
  11. Sampling Methods <br />
  12. Continuous Latent Variables <br />
  13. Sequential Data <br />
  14. Combining Models
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2Qzg7XB">
    The Elements of Statistical Learning, 2nd (2008)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Overview of Supervised Learning <br />
  3. Linear Methods of Regression <br />
  4. Linear Methods for Classification <br />
  5. Basis Expansion and Regularization <br />
  6. Kernel Smoothing Methods <br />
  7. Model Assessment and Selection <br />
  8. Model Inference and Averaging <br />
  9. Additive Models, Trees, and Related Methods <br />
  10. Boosting and Additive Trees <br />
  11. Neural Networks <br />
  12. Support Vector Machines and Flexible Discriminants <br />
  13. Prototype Methods and Nearest-Neighbors <br />
  14. Unsupervised Learning <br />
  15. Random Forests <br />
  16. Ensemble Learning <br />
  17. Undirected Graphical Models <br />
  18. High-Dimensional Problems : p>>N
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2rkDCph">
    Murphy, Machine Learning: A Probabilistic Perspective (2012)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Probability <br />
  3. Generative models for discrete data <br />
  4. Gaussian models <br />
  5. Bayesian statistics <br />
  6. Frequentist statistics <br />
  7. Linear regression <br />
  8. Logistic regression <br />
  9. Generalized linear models and the exponential family <br />
  10. Directed graphical models (Bayes nets) <br />
  11. Mixture models and the EM algorithm <br />
  12. Latent linear models <br />
  13. Sparse linear models <br />
  14. Kernels <br />
  15. Gaussian processes <br />
  16. Adaptive basis function models <br />
  17. Markov and hidden Markov models <br />
  18. State space models <br />
  19. Undirected graphical models (Markov random fields) <br />
  20. Exact inference for graphical models <br />
  21. Variational inference <br />
  22. More variational inference <br />
  23. Monte Carlo inference <br />
  24. Markov chain Monte Carlo (MCMC) inference <br />
  25. Clustering <br />
  26. Graphical model structure learning <br />
  27. Latent variable models for discrete data <br />
  28. Deep learning
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2RCNjuv">
    高村大也「言語処理のための機械学習入門」 (2010)
  </a>
  </p>

  <p>
  1. 必要な数学的知識 <br />
  2. 文書および単語の数学的表現 <br />
  3. クラスタリング <br />
  4. 分類 <br />
  5. 系列ラベリング <br />
  6. 実験の仕方など
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2RBefLp">
    「Pythonではじめる機械学習 - scikit-learnで学ぶ特徴量エンジニアリングと機械学習の基礎」 (2017)
  </a>
  </p>

  <p>
  1. はじめに <br />
  2. 教師あり学習 <br />
  3. 教師なし学習と前処理 <br />
  4. データの表現と特徴量エンジニアリング <br />
  5. モデルの評価と改良 <br />
  6. アルゴリズムチェーンとパイプライン <br />
  7. テキストデータの処理 <br />
  8. おわりに
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2ruvYJ7">
    「仕事ではじめる機械学習」 (2018)
  </a>
  </p>

  <p>
  1. 機械学習プロジェクトのはじめ方 <br />
  2. 機械学習で何ができる？ <br />
  3. 学習結果を評価しよう <br />
  4. システムに機械学習を組み込む <br />
  5. 学習のためのリソースを収集しよう <br />
  6. 効果検証 <br />
  7. 映画の推薦システムをつくる <br />
  8. Kickstarterの分析、機械学習を使わないという選択肢 <br />
  9. Uplift Modelingによるマーケティング資源の効率化
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2RBms29">
    Toby Segaran 「集合知プログラミング」 (2007, 2008)
  </a>
  </p>

  <p>
  1. 集合知への招待 <br />
  2. 推薦を行う <br />
  3. グループを見つけ出す <br />
  4. 検索とランキング <br />
  5. 最適化 <br />
  6. ドキュメントフィルタリング <br />
  7. 決定木によるモデリング <br />
  8. 価格モデルの構築 <br />
  9. 高度な分類手法：カーネルメソッドとSVM <br />
  10. 特徴を発見する <br />
  11. 進化する知性 <br />
  12. アルゴリズムのまとめ <br />
  A. サードパーティによるライブラリたち <br />
  B. 数式 <br />
  C. 日本語のテキスト処理
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2BCvhSF">
    麻生英樹・津田宏治・村田昇
    「パターン認識と学習の統計学 - 新しい概念と手法」 (2003, 2018)
  </a>
  </p>

  <p>
  <strong>I. パターン認識と学習</strong> <br />
  1. パターン認識と統計科学 <br />
  2. いろいろなパターン識別手法 <br />
  3. 統計的意思決定としてのパターン識別 <br />
  4. クラスタリングとベクトル量子化 <br />
  5. 時系列パターン情報の認識 <br />
  6. 学習と統計科学 <br />
  <br />
  <strong>II. カーネル法の理論と実際</strong> <br />
  1. カーネル法とは <br />
  2. カーネル関数と学習問題 <br />
  3. 教師つき学習のためのカーネル法 <br />
  4. 教師なし学習のカーネル法 <br />
  5. 事前知識を反映したカーネル <br />
  <br />
  <strong>III. 推定量を組み合わせる</strong> <br />
  1. 何が問題か <br />
  2. 組合せの方法 <br />
  3. モデルの拡大 <br />
  4. バギング <br />
  5. ブースティング
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2EW765F">
    杉山将
    「イラストで学ぶ 機械学習 最小二乗法による識別モデル学習を中心に」
    (2013)
  </a>
  </p>

  <p>
  <strong>I. はじめに</strong> <br />
  1. 機械学習とは <br />
  2. 学習モデル <br />
  <br />
  <strong>II. 教師付き回帰</strong> <br />
  3. 最小二乗学習 <br />
  4. 制約付き最小二乗学習 <br />
  5. スパース学習 <br />
  6. ロバスト学習 <br />
  <br />
  <strong>III. 教師付き分類</strong> <br />
  7. 最小二乗学習に基づく分類 <br />
  8. サポートベクトル分類 <br />
  9. アンサンブル分類 <br />
  10. 確率的分類 <br />
  11. 系列データの分類 <br />
  <br />
  <strong>IV. 教師なし学習</strong> <br />
  12. 異常検出 <br />
  13. 教師なし次元削減 <br />
  14. クラスタリング <br />
  <br />
  <strong>V. 発展的話題</strong> <br />
  15. オンライン学習 <br />
  16. 半教師付き学習 <br />
  17. 教師付き次元削減 <br />
  18. 転移学習 <br />
  19. マルチタスク学習 <br />
  <br />
  <strong>VI. おわりに</strong> <br />
  20. まとめと今後の展望
  </p>

  <hr />
  <p>
  <a href="../../index.html">ホーム</a>
  </p>

</body>
</html>

