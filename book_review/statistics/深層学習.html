<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/base.css">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/book_review.css">
  <title>miyake.github.io | 本の紹介 | 深層学習</title>
</head>

<body>

  <h1>本の紹介 : 深層学習</h1>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4048930621/ref=nosim?tag=msscee0a-22">
    Ian Goodfellow, Yoshua Bengio, Aaron Courville
    「深層学習」 (2018)
  </a>
  <br />
  原書 : <a href="https://www.deeplearningbook.org/">Deep Learning</a>
  </p>

  <p>
  1. はじめに <br />
  2. 線形代数 <br />
  3. 確率と情報理論 <br />
  4. 数値計算 <br />
  5. 機械学習の基礎 <br />
  6. 深層順伝播型ネットワーク <br />
  7. 深層学習のための正則化 <br />
  8. 深層モデルの訓練のための最適化 <br />
  9. 畳み込みネットワーク <br />
  10. 系列モデリング:回帰結合型ニューラルネットワークと再帰型ネットワーク <br />
  11. 実用的な方法論 <br />
  12. アプリケーション <br />
  13. 線形因子モデル <br />
  14. 自己符号化器 <br />
  15. 表現学習 <br />
  16. 深層学習のための構造化確率モデル <br />
  17. モンテカルロ法 <br />
  18. 分配関数との対峙 <br />
  19. 近似推論 <br />
  20. 深層生成モデル
  </p>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4061529021/ref=nosim?tag=msscee0a-22">
    岡谷貴之「深層学習」 (2015)
  </a>
  </p>

  <p>
  1. はじめに <br />
  2. 順伝播型ネットワーク <br />
  3. 確率的勾配降下法 <br />
  4. 誤差逆伝播法 <br />
  5. 自己符号化器 <br />
  6. 畳込みニューラルネット <br />
  7. 再帰型ニューラルネット <br />
  8. ボルツマンマシン
  </p>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4061538284/ref=nosim?tag=msscee0a-22">
    瀧雅人「これならわかる 深層学習入門」 (2017)
  </a>
  </p>

  <p>
  1. はじめに <br />
  2. 機械学習と深層学習 <br />
  3. ニューラルネット <br />
  4. 勾配降下法による学習 <br />
  5. 深層学習の正則化 <br />
  6. 誤差逆伝播法 <br />
  7. 自己符号化器 <br />
  8. 畳み込みニューラルネット <br />
  9. 再帰型ニューラルネット <br />
  10. ボルツマンマシン <br />
  11. 深層強化学習
  </p>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4873117585/ref=nosim?tag=msscee0a-22">
    斎藤康毅
    「ゼロから作るDeep Learning - Pythonで学ぶディープラーニングの理論と実装」
    (2016)
  </a>
  </p>

  <p>
  1. Python入門 <br />
  2. パーセプトロン <br />
  3. ニューラルネットワーク <br />
  4. ニューラルネットワークの学習 <br />
  5. 誤差逆伝播法 <br />
  6. 学習に関するテクニック <br />
  7. 畳み込みニューラルネットワーク <br />
  8. ディープラーニング <br />
  A. Softmax-with-Lossレイヤの計算グラフ
  </p>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4873118360/ref=nosim?tag=msscee0a-22">
    斎藤康毅
    「ゼロから作るDeep Learning 2 - 自然言語処理編」
    (2018)
  </a>
  </p>

  <p>
  1. ニューラルネットワークの復習 <br />
  2. 自然言語と単語の分散表現 <br />
  3. word2vec <br />
  4. word2vecの高速化 <br />
  5. リカレントニューラルネットワーク (RNN) <br />
  6. ゲート付きRNN <br />
  7. RNNによる文章生成 <br />
  8. Attention <br />
  A. sigmoid関数とtanh関数の微分 <br />
  B. WordNetを動かす <br />
  C. GRU
  </p>

  <hr />
  <p>
  <a href="https://www.amazon.co.jp/dp/4061529242/ref=nosim?tag=msscee0a-22">
    坪井祐太「深層学習による自然言語処理」 (2017)
  </a>
  </p>

  <p>
  1. 自然言語処理のアプローチ <br />
  2. ニューラルネットの基礎 <br />
  3. 言語処理における深層学習の基礎 <br />
  4. 言語処理特有の深層学習の発展 <br />
  5. 応用 <br />
  6. 汎化性能を向上させる技術 <br />
  7. 実装 <br />
  8. おわりに
  </p>

  <hr />
  <p>
  <a href="../../index.html">ホーム</a>
  </p>

</body>
</html>

