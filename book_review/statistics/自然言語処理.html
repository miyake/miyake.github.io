<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/base.css">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/book_review.css">
  <title>miyake.github.io | 本の紹介 | 自然言語処理</title>
</head>

<body>

  <h1>本の紹介 : 自然言語処理</h1>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4873114705/ref=nosim?tag=msscee0a-22">
    Steven Bird, Ewan Klein, Edward Loper 
    「入門 自然言語処理」 (2010)
  </a>
  </h3>

  <p class="toc">
  1. 言語処理とPython <br />
  2. テキストコーパスと語彙資源へのアクセス <br />
  3. 生テキストの処理 <br />
  4. 構造化されたプログラムを書く <br />
  5. 単語の分類とタグ付け <br />
  6. テキスト分類の学習 <br />
  7. テキストからの情報抽出 <br />
  8. 文構造の分析 <br />
  9. 素性ベースの文法の構築 <br />
  10. 文の意味の解析 <br />
  11. 言語データの管理 <br />
  12. Pythonによる日本語自然言語処理
  </p>

  <hr />
  <h3>
  <!--
  <a href="">
    人工知能学会 「人工知能学事典」 (2005)
  </a>
  -->
    人工知能学会 「人工知能学事典」 (2005)
  </h3>

  <p>
  第7章で自然言語処理が扱われています。
  </p>

  <p class="toc">
  1. 言語資源 (Language Resource) <br />
  2. 形態素解析と品詞タグつけ (Morphological Analysis and Part of Speech Tagging) <br />
  3. 統語解析アルゴリズム (Parsing Algorithm) <br />
  4. 統計的統語解析 (Statistical Parsing) <br />
  5. 文法 (Grammar) <br />
  6. チャンキング (Chunking) <br />
  7. 言語生成 (Language Generation) <br />
  8. 言い換え技術 (Paraphrasing Technology) <br />
  9. 意味処理 (Semantic Processing) <br />
  10. 語彙意味論 (Lexical Semantics) <br />
  11. 語義曖昧性解消 (Word Sense Disambiguation) <br />
  12. 言語知識獲得 (Linguistic Knowledge Acquisition) <br />
  13. 談話処理 (Discourse Processing) <br />
  14. 対話処理 (Dialog Processing) <br />
  15. 照応解析 (Anaphora Resolution) <br />
  16. 機械翻訳 (Machine Translation) <br />
  17. 統計的機械翻訳 (Statistical Machine Translation) <br />
  18. 2言語間アラインメント (Bilingual Alignment) <br />
  19. 情報検索 (Information Retrieval) <br />
  20. 適合性フィードバック (Relevance Feedback) <br />
  21. 他言語情報検索 (Multi-Lingual Information Retrieval) <br />
  22. 情報抽出 (Information Extraction) <br />
  23. 文書要約 (Text Summarization) <br />
  24. 文書分類 (Text Categorization) <br />
  25. テキストマイニング (1) (Text Mining (1))
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4339024511/ref=nosim?tag=msscee0a-22">
    奥村学 「自然言語処理の基礎」 (2010)
  </a>
  </h3>

  <p class="toc">
  1. 自然言語処理概論 <br />
  2. 辞書とコーパス <br />
  3. 形態素解析 <br />
  4. 構文解析 <br />
  5. 意味解析 <br />
  6. 文脈解析 <br />
  7. 自然言語処理の応用
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4339027510/ref=nosim?tag=msscee0a-22">
    高村大也「言語処理のための機械学習入門」 (2010)
  </a>
  </h3>

  <p class="toc">
  <strong>1. 必要な数学的知識</strong> <br />
  1. 準備と本書における約束事 <br />
  2. 最適化問題 <br />
  3. 確率 <br />
  4. 連続確率変数 <br />
  5. パラメータ推定法 <br />
  6. 情報理論 <br />
  <br />
  <strong>2. 文書および単語の数学的表現</strong> <br />
  1. タイプ，トークン <br />
  2. nグラム <br />
  3. 文書，文のベクトル表現 <br />
  4. 文書に対する前処理とデータスパースネス問題 <br />
  5. 単語のベクトル表現 <br />
  6. 文書や単語の確率分布による表現 <br />
  <br />
  <strong>3. クラスタリング</strong> <br />
  1. 準備 <br />
  2. 凝集型クラスタリング <br />
  3. k-平均法 <br />
  4. 混合正規分布によるクラスタリング <br />
  5. EMアルゴリズム <br />
  6. クラスタリングにおける問題点や注意点 <br />
  <br />
  <strong>4. 分類</strong> <br />
  1. 準備 <br />
  2. ナイーブベイズ分類器 <br />
  3. サポートベクトルマシン <br />
  4. カーネル法 <br />
  5. 対数線形モデル <br />
  6. 素性選択 <br />
  <br />
  <strong>5. 系列ラベリング</strong> <br />
  1. 準備 <br />
  2. 隠れマルコフモデル <br />
  3. 通常の分類器の逐次適用 <br />
  4. 条件付き確率場 <br />
  5. チャンキングへの適用の仕方 <br />
  <br />
  <strong>6. 実験の仕方など</strong> <br />
  1. プログラムとデータの入手 <br />
  2. 分類問題の実験の仕方 <br />
  3. 評価指標 <br />
  4. 検定
  </p>

  <hr />
  <h3>
  北研一 「確率的言語モデル」 (1999)
  </h3>

  <p class="toc">
  1. 序章 <br />
  2. 言語モデルの基礎 <br />
  3. Nグラムモデル <br />
  4. 隠れマルコフモデル <br />
  5. 確率文法 <br />
  6. 最大エントロピーモデル <br />
  7. 言語モデルの応用
  </p>

  <hr />
  <h3>
  金・村上・永田・大津・山西 「言語と心理の統計」 (2003)
  </h3>

  <p class="toc">
  <strong>第I部 文章の統計分析とは (金明哲・村上征勝)</strong> <br />
  1. 文章の統計分析と著者推定 <br />
  2. 文章の特徴抽出 <br />
  3. 統計分析方法 <br />
  4. 日本語の文章の統計分析 <br />
  5. 展望と文献案内 <br />
  <br />
  <strong>第II部 確率モデルによる自然言語処理 (永田昌明)</strong> <br />
  1. 人工知能的アプローチから確率・統計的アプローチへ <br />
  2. 形態素解析 <br />
  3. 固有表現抽出 <br />
  4. テキスト分類 <br />
  5. 統計的機械翻訳 <br />
  <br />
  <strong>第III部 社会調査データからの推論：実践的入門 (大津起夫)</strong> <br />
  1. 調査データから何が推論できるか？ <br />
  2. NSLY79と“The Bell Curve”論争 <br />
  3. 主成分分析と特異値分解 <br />
  4. 対応分析 <br />
  5. 連関モデル <br />
  6. 多重対応分析 <br />
  7. 尺度最適化を伴う主成分分析 <br />
  8. おわりに <br />
  <br />
  <strong>第IV部 データとテキストのマイニング (山西健司)</strong> <br />
  1. データマイニングとは <br />
  2. バスケット分析 <br />
  3. 分類ルールの学習 <br />
  4. 嗜好学習とリコメンデーション <br />
  5. 外れ値検出と不正検出 <br />
  6. データマイニングその他の話題 <br />
  7. テキスト分類と自由記述アンケート分析 <br />
  8. Webマイニング <br />
  9. おわりに <br />
  A.1. 確率的コンプレキシティ <br />
  A.2. 拡張型確率的コンプレキシティ
  </p>


  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4339027626/ref=nosim?tag=msscee0a-22">
    荒牧英治 「医療言語処理」 (2017)
  </a>
  </h3>

  <p class="toc">
  1. 医療情報の利活用とは <br />
  2. 利用可能なリソース・ツール <br />
  3. 病院内テキスト <br />
  4. パブリックデータ: 公開テキストの医療言語処理 <br />
  5. プライベートデータ: 患者テキストの医療言語処理 <br />
  6. これからの医療言語処理研究
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/479812852X/ref=nosim?tag=msscee0a-22">
    奥野陽, グラム・ニュービッグ, 萩原正人
    「自然言語処理の基本と技術」 (2016)
  </a>
  </h3>

  <p class="toc">
  1. 自然言語処理の概要 <br />
  2. 自然言語処理の基礎知識 <br />
  3. 日本語入力と自然言語処理 <br />
  4. 機械翻訳 <br />
  5. 情報検索 <br />
  6. Webと自然言語処理 <br />
  7. 自然言語処理のこれから
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4774149934/ref=nosim?tag=msscee0a-22">
    徳永拓之 「日本語入力を支える技術」 (2012)
  </a>
  </h3>

  <p class="toc">
  1. 日本語と日本語入力システムの歩み <br />
  2. 日本語入力システムの概観 <br />
  3. かな漢字変換エンジンに用いられるデータ構造 <br />
  4. かな漢字変換システムの実装 <br />
  5. 統計・機械学習のアルゴリズムとその応用 <br />
  6. 日本語入力のこれから
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4781913881/ref=nosim?tag=msscee0a-22">
    黒橋禎夫, 柴田知秀 「自然言語処理概論」 (2016)
  </a>
  </h3>

  <p class="toc">
  1. はじめに <br />
  2. 系列の解析 <br />
  3. 構文の解析 <br />
  4. 意味の解析 <br />
  5. 文脈の解析 <br />
  6. ニューラルネットワークの利用 <br />
  7. 情報抽出と知識獲得 <br />
  8. 情報検索 <br />
  9. トピックモデル <br />
  10. 機械翻訳 <br />
  11. 対話システム <br />
  12. まとめ
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4873118360/ref=nosim?tag=msscee0a-22">
    斎藤康毅
    「ゼロから作るDeep Learning 2 - 自然言語処理編」
    (2018)
  </a>
  </h3>

  <p class="toc">
  1. ニューラルネットワークの復習 <br />
  2. 自然言語と単語の分散表現 <br />
  3. word2vec <br />
  4. word2vecの高速化 <br />
  5. リカレントニューラルネットワーク (RNN) <br />
  6. ゲート付きRNN <br />
  7. RNNによる文章生成 <br />
  8. Attention <br />
  A. sigmoid関数とtanh関数の微分 <br />
  B. WordNetを動かす <br />
  C. GRU
  </p>

  <hr />
  <h3>
  <a href="https://www.amazon.co.jp/dp/4873115124/ref=nosim?tag=msscee0a-22">
    Lin & Dyer 「Hadoop MapReduce デザインパターン - MapReduce による大規模テキストデータ処理」 (2010, 2011)
  </a>
  </h3>

  <p class="toc">
  1. イントロダクション <br />
  2. MapReduce の基礎 <br />
  3. MapReduce アルゴリズムの設計 <br />
  4. テキスト抽出のための転置インデックスの生成 <br />
  5. グラフのアルゴリズム <br />
  6. テキスト処理のための EMアルゴリズム <br />
  7. 未来に向かって
  </p>

  <hr />
  <p>
  <a href="../../index.html">ホーム</a>
  </p>

</body>
</html>

