<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="../../stylesheets/base.css">
  <title>miyake.github.io | 本の紹介 | パターン認識</title>
</head>

<body>

  <h1>本の紹介 : パターン認識</h1>

  <hr />
  <p>
  <a href="https://amzn.to/2BKmKNB">
  平井有三「はじめてのパターン認識」 (2012)
  </a>
  </p>

  <p>
  1. はじめに <br />
  2. 識別規則と学習法の概要 <br />
  3. ベイズの識別規則 <br />
  4. 確率モデルと識別関数 <br />
  5. k最近傍法 (kNN法) <br />
  6. 線形識別関数 <br />
  7. パーセプトロン型学習規則 <br />
  8. サポートベクトルマシン <br />
  9. 部分空間法 <br />
  10. クラスタリング <br />
  11. 識別器の組み合わせによる性能強化 <br />
  A. ベクトルと行列による微分
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2Ad7Gb2">
    石井健一郎・前田英作・上田修功・村瀬洋
    「わかりやすいパターン認識」 (1998)
  </a>
  </p>

  <p>
  1. パターン認識とは <br />
  2. 学習と識別関数 <br />
  3. 誤差評価に基づく学習 <br />
  4. 識別部の設計 <br />
  5. 特徴の評価とベイズ誤り確率 <br />
  6. 特徴空間の変換 <br />
  7. 部分空間法 <br />
  8. 学習アルゴリズムの一般化 <br />
  9. 学習アルゴリズムとベイズ決定則
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2Abzrkd">
    石井健一郎・上田修功
    「続・わかりやすいパターン認識 - 教師なし学習入門」 (2014)
  </a>
  </p>

  <p>
  1. ベイズ統計学 <br />
  2. 事前確率と事後確率 <br />
  3. ベイズ決定則 <br />
  4. パラメータ推定 <br />
  5. 教師付き学習と教師なし学習 <br />
  6. EMアルゴリズム <br />
  7. マルコフモデル <br />
  8. 隠れマルコフモデル <br />
  9. 混合分布のパラメータ推定 <br />
  10. クラスタリング <br />
  11. ノンパラメトリックベイズモデル <br />
  12. ディリクレ過程混合モデルによるクラスタリング <br />
  13. 共クラスタリング
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2Aam2Jw">
    金森敬文・竹之内高志・村田昇
    「パターン認識 (Rで学ぶデータサイエンス 5)」 (2009)
  </a>
  </p>

  <p>
  1. 判別能力の評価 <br />
  2. k-平均法 <br />
  3. 階層的クラスタリング <br />
  4. 混合正規分布モデル <br />
  5. 判別分析 <br />
  6. ロジスティック回帰 <br />
  7. 密度推定 <br />
  8. k-近傍法 <br />
  9. 学習ベクトル量子化 <br />
  10. 決定木 <br />
  11. サポートベクターマシン <br />
  12. 正則化とパス追跡アルゴリズム <br />
  13. ミニマックス確率マシン <br />
  14. 集団学習 <br />
  15. 2値判別から多値判別へ
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2rldoTq">
    Bishop, Pattern Recognition and Machine Learning (2006)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Probability Distributions <br />
  3. Linear Models for Regression <br />
  4. Linear Models for Classification <br />
  5. Neural Networks <br />
  6. Kernel Methods <br />
  7. Sparse Kernel Machines <br />
  8. Graphical Models <br />
  9. Mixture Models and EM <br />
  10. Approximate Inference <br />
  11. Sampling Methods <br />
  12. Continuous Latent Variables <br />
  13. Sequential Data <br />
  14. Combining Models
  </p>

  <p>
  <a href="https://amzn.to/2RBpO50">「パターン認識と機械学習 上」</a>
  <a href="https://amzn.to/2rhY61U">「パターン認識と機械学習 下」</a>
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2Qzg7XB">
    The Elements of Statistical Learning, 2nd (2008)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Overview of Supervised Learning <br />
  3. Linear Methods of Regression <br />
  4. Linear Methods for Classification <br />
  5. Basis Expansion and Regularization <br />
  6. Kernel Smoothing Methods <br />
  7. Model Assessment and Selection <br />
  8. Model Inference and Averaging <br />
  9. Additive Models, Trees, and Related Methods <br />
  10. Boosting and Additive Trees <br />
  11. Neural Networks <br />
  12. Support Vector Machines and Flexible Discriminants <br />
  13. Prototype Methods and Nearest-Neighbors <br />
  14. Unsupervised Learning <br />
  15. Random Forests <br />
  16. Ensemble Learning <br />
  17. Undirected Graphical Models <br />
  18. High-Dimensional Problems : p>>N
  </p>

  <hr />
  <p>
  <a href="https://amzn.to/2rkDCph">
    Murphy, Machine Learning: A Probabilistic Perspective (2012)
  </a>
  </p>

  <p>
  1. Introduction <br />
  2. Probability <br />
  3. Generative models for discrete data <br />
  4. Gaussian models <br />
  5. Bayesian statistics <br />
  6. Frequentist statistics <br />
  7. Linear regression <br />
  8. Logistic regression <br />
  9. Generalized linear models and the exponential family <br />
  10. Directed graphical models (Bayes nets) <br />
  11. Mixture models and the EM algorithm <br />
  12. Latent linear models <br />
  13. Sparse linear models <br />
  14. Kernels <br />
  15. Gaussian processes <br />
  16. Adaptive basis function models <br />
  17. Markov and hidden Markov models <br />
  18. State space models <br />
  19. Undirected graphical models (Markov random fields) <br />
  20. Exact inference for graphical models <br />
  21. Variational inference <br />
  22. More variational inference <br />
  23. Monte Carlo inference <br />
  24. Markov chain Monte Carlo (MCMC) inference <br />
  25. Clustering <br />
  26. Graphical model structure learning <br />
  27. Latent variable models for discrete data <br />
  28. Deep learning
  </p>

  <hr />
  <p>
  <a href="../../index.html">ホーム</a>
  </p>

</body>
</html>

